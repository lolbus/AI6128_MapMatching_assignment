{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d9817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c4a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(source_file_path, target_file_path, sample_num):\n",
    "    source_csv = open(source_file_path, 'r')\n",
    "    dict_reader = csv.DictReader(source_csv)\n",
    "    \n",
    "    target_csv = open(target_file_path, 'w', newline='')\n",
    "    file_header = ['TRIP_ID', 'CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'TAXI_ID', 'TIMESTAMP', 'DAY_TYPE', 'MISSING_DATA', 'POLYLINE', \n",
    "                  'MIN_LONG', 'MAX_LONG', 'MIN_LAT', 'MAX_LAT']\n",
    "    dict_writer = csv.DictWriter(target_csv, file_header)\n",
    "    dict_writer.writerow(dict(zip(file_header, file_header)))\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for item in dict_reader:\n",
    "        if counter >= sample_num:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        if(len(eval(item['POLYLINE'])) == 0):\n",
    "            continue\n",
    "            \n",
    "        polyline = np.array(eval(item['POLYLINE']))\n",
    "        min_data = np.min(polyline, axis=0)\n",
    "        max_data = np.max(polyline, axis=0)\n",
    "        \n",
    "        item['MIN_LONG'] = min_data[0]\n",
    "        item['MAX_LONG'] = max_data[0]\n",
    "        item['MIN_LAT'] = min_data[1]\n",
    "        item['MAX_LAT'] = max_data[1]\n",
    "        \n",
    "        item['TRIP_ID'] = item['TRIP_ID'] + '\\t'\n",
    "        \n",
    "        \n",
    "        dict_writer.writerow(item)\n",
    "        counter += 1\n",
    "        \n",
    "    source_csv.close()\n",
    "    target_csv.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe2205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_csv(source_file_path, target_file_path):\n",
    "    source_csv = open(source_file_path, 'r')\n",
    "    dict_reader = csv.DictReader(source_csv)\n",
    "    \n",
    "    target_csv = open(target_file_path, 'w', newline='')\n",
    "    file_header = ['id;geom']\n",
    "    writer = csv.writer(target_csv)\n",
    "    \n",
    "    writer.writerow(file_header)\n",
    "    for item in dict_reader:\n",
    "        row = []\n",
    "        polyline = eval(item['POLYLINE'])\n",
    "        trip_id = item['TRIP_ID'].strip()\n",
    "        row.append('{};LINESTRING({} {}'.format(trip_id, polyline[0][0], polyline[0][1]))\n",
    "        for i in range(1, len(polyline) - 1):\n",
    "            row.append('{} {}'.format(polyline[i][0], polyline[i][1]))\n",
    "        row.append('{} {})'.format(polyline[len(polyline) - 1][0], polyline[len(polyline) - 1][1]))\n",
    "        writer.writerow(row)\n",
    "        \n",
    "    source_csv.close()\n",
    "    target_csv.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d39616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_txt(source_file_path, target_file_path):\n",
    "    source_csv = open(source_file_path, 'r')\n",
    "    dict_reader = csv.DictReader(source_csv)\n",
    "    \n",
    "    target_txt = open(target_file_path, 'w')\n",
    "    file_header = 'id;geom;timestamp\\n'\n",
    "    \n",
    "    target_txt.write(file_header)\n",
    "    for (i, item) in enumerate(dict_reader):\n",
    "        row = '{};LINESTRING('.format(i + 1)\n",
    "        polyline = eval(item['POLYLINE'])\n",
    "        \n",
    "        for j in range(0, len(polyline)):\n",
    "            row = row + '{} {},'.format(polyline[j][0], polyline[j][1])\n",
    "        row = row[:len(row) - 1] + ');{}\\n'.format(item['TIMESTAMP'])\n",
    "        target_txt.write(row)\n",
    "    target_txt.close()\n",
    "    source_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03b54464",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data('data/train.csv', 'data/train_1000.csv', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a581cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_data_csv('data/train_1000.csv', 'data/trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c979d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_data_txt('data/train_1000.csv', 'data/trips.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d6e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
